版本更新说明

## v0.0.11

v0.0.10的第2个修复理解有误，实际上在\author和\begin{table}包裹的命令中，对换行符很敏感，因为涉及到一些对齐问题。所以每次移除"%"注释必须完全移除。但对于需要的空行也不能随意更改，否则也会触发编译错误，如：
```latex
\begin{table}[t]
    \centering
    \begin{tabular}{p{100mm}}
    \toprule
    你是一个标签系统，为指令意图提供有用的标签，以区分有用的AI助手的指令。以下是一个指令：\\
    
    [begin]
    
    \{instruction\}
    
    [end]
    
    请提供粗粒度标签，例如“拼写和语法检查”和“角色扮演”，以识别上述指令的主要意图。
    你的回答应该是一个列表，包括标签的标题和每个标签的简要说明。
    你的回答必须严格遵循此JSON格式：[{"tag": str, "explanation": str}]。
    请用英语回答。 \\
    \bottomrule
    \end{tabular}
    \caption{\textsc{ChatGPT} 用于注释给定查询意图标签的提示模板。}
    \label{tab:tagging_prompt}
\end{table}
```

这里面\[begin\]前面的两个换行符不可以随意移除，否则会编译错误。

因此这版撤销v0.0.10的第2个改动，转为对\author和\begin{table}包裹的命令使用严格的单行注释清除。

另外，`\pdfToLatex=1`这个命令对于xelatex没啥用，可以直接移除掉。

## v0.0.10

修复了两个可能比较常见的bad case

1. 没有参数的命令和中文粘连的问题

比如，翻译后的文本:
```latex
基于这一观察，我们提出了一种基于\modelname的数据选择器，从开源数据集中选择6K个多样且复杂的样本，并在\modelname选择的数据上微调模型。
最终的模型\lmname在\textsc{MT-Bench}评估的基础上，超越了基于大规模SFT数据的开源模型，呼应了查询多样性和复杂性的重要性。
```
看着没啥问题，但编译时会把`\modelname`解读为`\modelname的数据选择器`从而编译出现问题。在本版本应用了后处理，通过给它们前后添加空格来避免编译时的歧义。处理后的文本:
```latex
基于这一观察，我们提出了一种基于 \modelname 的数据选择器，从开源数据集中选择6K个多样且复杂的样本，并在 \modelname 选择的数据上微调模型。
最终的模型 \lmname 在 \textsc{MT-Bench} 评估的基础上，超越了基于大规模SFT数据的开源模型，呼应了查询多样性和复杂性的重要性。
```

2. `\\`与注释移除带来的异常空格问题

出于节省token的考虑，在预处理时移除了注释，但为了保留一部分可读性便于后面编辑，只是把注释那行变成了空白行。这在大多数用例里都没有问题，但似乎和`\\`同时使用会出现编译问题。例如:
```latex
\author{Author 1 \& Author 2 \& Author 3 \&
机构名 \\
% 原来有的注释
}
```
预处理后变成:
```latex
\author{Author 1 \& Author 2 \& Author 3 \&
机构名 \\

}
```
这样居然会报错了，我们在这个版本用正则表达式手动移除`\\`后多余的换行符来减少编译错误。

## v0.0.9

该版本主要进行了如下改动：
- 针对gpt-4o-mini会在\end{abstract}后补充\end{document}的特定case，进行了一些启发式方法进行预防。
- 对于一些直接提供了`.bbl`而没有提供`.bib`文件的latex项目进行了编译优化。跳过`bibtex`编译并直接把`.bbl`目录复制到输出目录。

## v0.0.8

推荐切换到gpt-4o-mini，速度快，价格没有那么夸张而且效果好。

另外，还进行了一些常规更新和修改：
- arxiv论文翻译时默认用论文标题作为文件夹路径。
- 默认切换到gpt-4o-mini和openai官方api端点。
- 将默认qps降低为3。


## v0.0.7

修复请求时产生的错误，具体如下：

- 修复触发`429限额错误`时将`status_code`解析成字符串而不是整数的错误。
- 修复重试时失败任务下标错误。
- 修复因触发LLM风控，导致意外退出的问题。目前解决方案是如果触发LLM风控，则该部分回退到Latex原文。触发风控的代码参考deepseek设置为400。
- 将重试轮数从3轮更改为10轮，降低因模型qps低而导致整体结果不可用的概率。

## v0.0.6

修改了latex项目翻译的逻辑。之前是按tex文件依次调用API进行翻译的，因此在子tex文件较多而且文件内容较短时的时候会接近串行请求。目前修改为先获取整个项目要翻译的tex片段之后统一请求，请求完了之后再进行相应的后处理，对于子tex文件较多的项目可以缩短等待时间。(速度优化)

## v0.0.5

新增了更多命令的吸收，并且合并了相邻占位符，希望能够带来更好的翻译输出。

- 新增吸收\def和\newcommand命令，避免LLM错误修改导致编译问题。
- 合并相邻的占位符，减少LLM复制大块占位符时产生的幻觉。
- 新增处理\`\`\`的逻辑，可以减少deepseek等模型无中生有\`\`\`产生的问题。